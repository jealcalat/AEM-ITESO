En todos los casos, pueden buscar bases de datos en el repositorio de [Kaggle](https://www.kaggle.com/datasets) o en el repositorio de [UCI](https://archive.ics.uci.edu/).



# Análisis de componentes principales: 21 de noviembre

    1. Introducción general a métodos no supervisados.
    2. Estructura matemática (combinación lineal).
    3. Método de obtención con factorización matricial.
    4. Implementación e interpretación en Python

Referencias:

- [An Introduction to Statistical Learning](https://hastie.su.domains/ISLP/ISLP_website.pdf) (ver Capítulo 12 y 12.2, y para la implementación, ver sección 12.5).

# Análisis de clúster: 23 de noviembre

    1. Estructura matemática (distancia euclidiana, distancia de Mahalanobis, etc).
    2. Métricas (e.g., distancia intra-cluster, distancia inter-cluster, etc) y métodos usados para seleccionar el número óptimo de clusters (e.g., método del codo, método de la silueta, etc).
    3. Implementación e interpretación en Python.

Referencias:

- [An Introduction to Statistical Learning](https://hastie.su.domains/ISLP/ISLP_website.pdf) (ver Capítulo 12 y 12.4, y para la implementación, ver sección 12.5).


--- 

# Regresión lineal múltiple: 

	1. Estructura general del modelo de regresión.
	2. Selección de variables por medio de AIC ó BIC. Por ejemplo, hacer 4 modelos diferentes, quitando en cada uno de ellos una variable a la vez, luego comparar los modelos con AIC ó BIC.
	3. Seleccionar el mejor modelo.
    4. Interpretación de los coeficientes de regresión (los betas).

Referencias:

- [An Introduction to Statistical Learning](https://hastie.su.domains/ISLP/ISLP_website.pdf) (ver Capítulo 3, y para la implementación, ver sección 3.6).
- Pueden ver algún ejemplo de Kaggle para seleccionar una base de datos para sus ejemplos. 

# Regresión logística: 

    1. Modelos lineales generalizados (énfasis en función de enlace).
    2. Implementación y diagnóstico de modelo de regresión logística en Python.
    3. Interpretación de resultados (efectos marginales, odds ratio, intervalos de confianza, etc).

Referencias:

- [An Introduction to Statistical Learning](https://hastie.su.domains/ISLP/ISLP_website.pdf) (ver Capítulo 4 y 4.4, y para la implementación, ver sección 4.7).
